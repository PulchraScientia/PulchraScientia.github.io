---
published: true
layout: single
title: "Loss Function"
---

## Loss
* Loss(손실값: 원하는 출력값 target, y 와 실제 출력값 output, $\hat{y}$ 차이의 합

$$Loss = \sum^{N}_ {i=1}||y_{i} - \hat{y}_ {i}||$$

$$ \sum^{N}_ {i=1}||y_ i - f(x_ i)||$$

Loss가 작을수록 가상의 함수를 잘 모사하고 있다 -> 선택

## Loss Function
* Linear Layer의 파라미터를 바꿀때마다 Loss를 계산
* Loss Function
  * 입력 : Linear Layer의 파라미터
  * 출력 : Loss
$$\mathcal{L}(\theta) = \sum^{N}_ {i=1}||y_ {i} - f_ {\theta}(x_ i)||$$
$$where \quad \theta = {W, b}.$$

## Euclidean Distance
* 두 점 사이의 거리
* 차원이 상승했을때 대응이 어려움 
$$||y - \hat{y}||_ {2} = \sqrt{(y_ 1 - \hat{y_1}^2 + \cdots +(y_ n - \hat{y_ n})^2,)}$$

$$ = \sqrt{\sum^n_ {i = 1}(y - \hat{y_i})^2}$$

$$where \quad y \in \mathbb R^n \quad and \quad \hat{y} \in \mathbb R^n$$


## RMSE
$$RMSE(y, \hat{y}) = \sqrt{\frac{1}{n}\sum^n_ {i=1}{(y_ i - \hat{y_ i})^2}}$$

## MSE
* Root와 상수를 뺐지만, 크기 차이로 인한 순서 결과는 바뀌지 않음.

$$
\begin{aligned}
MSE(y, \hat{y}) &= \frac{1}{n}\sum^n_ {i=1}(y_ i - \hat{y_ i})^2\\
&= \frac{1}{n}(||y - \hat{y}||_ 2)\\
&= \frac{1}{n}||y- \hat{y}||_ 2^2\\
&\propto ||y-\hat{y}||_2 ^2\\
\end{aligned}$$
